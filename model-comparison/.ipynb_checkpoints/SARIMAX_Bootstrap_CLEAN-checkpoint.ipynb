{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e4fc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports (consolidated)\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc30518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (centralized)\n",
    "HORIZON = 15          # forecast horizon (days/periods)\n",
    "N_SIMS = 500          # number of bootstrap simulations\n",
    "RANDOM_SEED = 42      # random seed for reproducibility\n",
    "CAP_AT_ZERO = False   # cap simulated forecasts at zero\n",
    "\n",
    "# SARIMAX configuration\n",
    "ORDER = (1, 0, 0)\n",
    "SEASONAL_ORDER = (0, 0, 0, 0)\n",
    "ENFORCE_STATIONARITY = True\n",
    "ENFORCE_INVERTIBILITY = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aca311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter validation\n",
    "assert isinstance(HORIZON, int) and HORIZON > 0, \"HORIZON must be a positive integer.\"\n",
    "assert isinstance(N_SIMS, int) and N_SIMS > 0, \"N_SIMS must be a positive integer.\"\n",
    "assert isinstance(RANDOM_SEED, int) and RANDOM_SEED >= 0, \"RANDOM_SEED must be a non-negative integer.\"\n",
    "assert isinstance(CAP_AT_ZERO, bool), \"CAP_AT_ZERO must be boolean.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfafca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions (refactor for clarity)\n",
    "\n",
    "def evaluate_model(y_true, y_pred, name=\"model\"):\n",
    "    \"\"\"Return MAE and RMSE for quick evaluation.\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    return {\"name\": name, \"MAE\": mae, \"RMSE\": rmse}\n",
    "\n",
    "def fit_sarimax(series, order=(1,0,0), seasonal_order=(0,0,0,0), exog=None, enforce_stationarity=True, enforce_invertibility=True):\n",
    "    \"\"\"Fit a SARIMAX model and return the fitted result.\"\"\"\n",
    "    model = SARIMAX(\n",
    "        series, \n",
    "        order=order, \n",
    "        seasonal_order=seasonal_order, \n",
    "        exog=exog, \n",
    "        enforce_stationarity=enforce_stationarity, \n",
    "        enforce_invertibility=enforce_invertibility\n",
    "    )\n",
    "    return model.fit(disp=False)\n",
    "\n",
    "def bootstrap_residual_forecast(fitted, horizon, n_sims=500, cap_at_zero=False, random_seed=None):\n",
    "    \"\"\"\n",
    "    Residual bootstrap on the fitted SARIMAX model.\n",
    "    Returns dict with: mean_fc, lower, upper, sims (array of shape n_sims x horizon).\n",
    "    \"\"\"\n",
    "    if random_seed is not None:\n",
    "        rng = np.random.default_rng(random_seed)\n",
    "    else:\n",
    "        rng = np.random.default_rng()\n",
    "        \n",
    "    # In-sample residuals\n",
    "    resid = fitted.resid.copy()\n",
    "    resid = resid[~np.isnan(resid)]\n",
    "    if resid.size == 0:\n",
    "        raise ValueError(\"No residuals available for bootstrap.\")\n",
    "        \n",
    "    # Forecast baseline (deterministic)\n",
    "    baseline = fitted.get_forecast(steps=horizon)\n",
    "    baseline_mean = baseline.predicted_mean.values.astype(float)\n",
    "    \n",
    "    # Draw bootstrap residual paths\n",
    "    sims = np.zeros((n_sims, horizon), dtype=float)\n",
    "    for i in range(n_sims):\n",
    "        noise = rng.choice(resid, size=horizon, replace=True)\n",
    "        sims[i, :] = baseline_mean + noise\n",
    "        if cap_at_zero:\n",
    "            sims[i, :] = np.maximum(sims[i, :], 0.0)\n",
    "            \n",
    "    mean_fc = sims.mean(axis=0)\n",
    "    lower = np.percentile(sims, 2.5, axis=0)\n",
    "    upper = np.percentile(sims, 97.5, axis=0)\n",
    "    return {\n",
    "        \"mean_fc\": mean_fc,\n",
    "        \"lower\": lower,\n",
    "        \"upper\": upper,\n",
    "        \"sims\": sims\n",
    "    }\n",
    "\n",
    "def plot_forecast(dates, history, forecast_mean, lower, upper, title=\"15-day forecast with SARIMAX + Residual Bootstrap\"):\n",
    "    \"\"\"Plot history and forecast with uncertainty bands.\"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.index, history.values, label=\"History\")\n",
    "    plt.plot(dates, forecast_mean, linewidth=2, label=\"Forecast (mean)\")\n",
    "    plt.fill_between(dates, lower, upper, alpha=0.2, label=\"95% band\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_backtest(dates, y_true, y_pred, title=\"Backtest: SARIMAX + Bootstrap\"):\n",
    "    \"\"\"Backtest plot of true vs predicted.\"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(dates, y_true, label=\"Actual\")\n",
    "    plt.plot(dates, y_pred, label=\"Predicted\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207798ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward-compatibility alias\n",
    "try:\n",
    "    eval_model\n",
    "except NameError:\n",
    "    def eval_model(true, pred, name=\"model\"):\n",
    "        return evaluate_model(true, pred, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb399e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ruta_base = '/Users/anapaulaelizondo/Desktop/Cosmos/data/'\n",
    "\n",
    "# Cargar datasets\n",
    "sales = pd.read_csv(f'{ruta_base}/Total_sales_per_product.csv')\n",
    "conversion = pd.read_csv(f'{ruta_base}/conversion_rate.csv')\n",
    "\n",
    "# --- Limpieza de sales ---\n",
    "sales = sales.drop(columns=[\n",
    "    'Nombre del producto', 'title de variante de producto', 'sales brutas', 'Descuentos', 'Devoluciones',\n",
    "    'sales netas', 'Impuestos', 'sales totales','SKU de variante de producto'])\n",
    "sales = sales.rename(columns={\n",
    "    'Día': 'day', 'Artículos netos vendidos': 'total_sales'})\n",
    "sales[\"day\"] = pd.to_datetime(sales[\"day\"], format=\"%d/%m/%y\", errors='coerce')\n",
    "sales = sales.dropna(subset=['day'])\n",
    "sales['total_sales'] = sales['total_sales'].apply(lambda x: max(x, 0))\n",
    "\n",
    "# --- Limpieza de conversion ---\n",
    "conversion = conversion.drop(columns=[\n",
    "    'Sesiones con adiciones al carrito', 'Sesiones en las que se llegó a la pantalla de pago', 'Day (previous_period)', 'Sessions (previous_period)',\n",
    "    'Sessions with cart additions (previous_period)', 'Sessions that reached checkout (previous_period)',\n",
    "    'Sessions that completed checkout (previous_period)', 'Conversion rate (previous_period)',\n",
    "    'Sesiones en las que se completó el pago','Tasa de conversión'])\n",
    "conversion = conversion.rename(columns={'Día': 'day','Sesiones': 'total_sessions'})\n",
    "conversion[\"day\"] = pd.to_datetime(conversion[\"day\"], format=\"%Y-%m-%d\", errors='coerce')\n",
    "conversion = conversion.dropna(subset=['day'])\n",
    "\n",
    "# --- Crear dataset combinado ---\n",
    "combined = (pd.merge(sales, conversion, on='day', how='outer')).fillna(0)\n",
    "combined['conversion_rate'] = (combined['total_sales'] / combined['total_sessions']).fillna(0)\n",
    "combined['conversion_rate'] = combined['conversion_rate'].round(3)\n",
    "\n",
    "\n",
    "# Agrupamos por día:\n",
    "combined = (combined.groupby('day', as_index=False).agg({\n",
    "          'total_sales':   'sum', 'total_sessions':'first'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd52604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation\n",
    "r = combined['total_sales'].corr(combined['total_sessions'])\n",
    "print(\"Pearson r:\", r.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7131abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Prepare series\n",
    "ts = combined.set_index('day')['total_sessions'].asfreq('D')  # índice datetime diario\n",
    "ts = ts.fillna(method='ffill')  # o interpolación para huecos\n",
    "\n",
    "# 2. Autocorrelations inspections (choose p,q,P,Q)\n",
    "plot_acf(ts, lags=30); plt.show()\n",
    "plot_pacf(ts, lags=30); plt.show()\n",
    "\n",
    "# 3. Define SARIMA:\n",
    "#    (p,d,q) x (P,D,Q,s)\n",
    "ORDER = (1,1,1)          # tests multiple values\n",
    "SEASONAL_ORDER = (1,1,1,7)  # weekly stationality\n",
    "\n",
    "model = SARIMAX(ts,\n",
    "                ORDER=ORDER,\n",
    "                SEASONAL_ORDER=SEASONAL_ORDER,\n",
    "                ENFORCE_STATIONARITY=False,\n",
    "                ENFORCE_INVERTIBILITY=False)\n",
    "fit = model.fit(disp=False)\n",
    "\n",
    "print(fit.summary())\n",
    "\n",
    "# 4. Residual diagnosis\n",
    "fit.plot_diagnostics(figsize=(12,8))\n",
    "plt.show()\n",
    "\n",
    "# 5. Forecast\n",
    "n_forecast = 30\n",
    "pred = fit.get_forecast(steps=n_forecast)\n",
    "forecast_sessions = pred.predicted_mean\n",
    "conf_int = pred.conf_int()\n",
    "\n",
    "# 6. Prediction visualization\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(ts.index, ts, label='Histórico')\n",
    "plt.plot(forecast_sessions.index, forecast_sessions, label='Forecast')\n",
    "plt.fill_between(conf_int.index,\n",
    "                 conf_int.iloc[:,0], conf_int.iloc[:,1],\n",
    "                 color='gray', alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 7. Estima sales usando conversion rate promedio\n",
    "cr_prom = (combined['total_sales'] / combined['total_sessions']).mean()\n",
    "forecast_sales = forecast_sessions * cr_prom\n",
    "\n",
    "print(\"Conversion rate promedio:\", cr_prom)\n",
    "print(\"Forecast de sales para próximos días:\")\n",
    "print(forecast_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0b4364",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Carga tu DataFrame combinado\n",
    "combined_copy = combined.copy()\n",
    "\n",
    "# 2. Lee tu CSV de insalesrio\n",
    "inventory = pd.read_csv(f\"{ruta_base}/inventory_summary.csv\")\n",
    "\n",
    "# 3. Convierte la columna de date (\"Día\") a datetime y renómbrala\n",
    "inventory['day'] = pd.to_datetime(inventory['Día'], dayfirst=True)\n",
    "\n",
    "# 4. Agrupa por día sumando el insalesrio\n",
    "inv_daily = (\n",
    "    inventory\n",
    "      .groupby('day', as_index=False)\n",
    "      .agg({'Unidades de insalesrio finales': 'sum'})\n",
    "      .rename(columns={'Unidades de insalesrio finales': 'inventory'})\n",
    ")\n",
    "\n",
    "# 5. Asegura que la columna 'day' de tu copia sea datetime\n",
    "combined_copy['day'] = pd.to_datetime(combined_copy['day'])\n",
    "\n",
    "# 6. Merge para incorporar la nueva columna 'inventory'\n",
    "combined_copy = (\n",
    "    combined_copy\n",
    "      .merge(inv_daily, on='day', how='left')\n",
    "      .fillna({'inventory': 0}))\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 7. Forzar inventory = 0 en las date indicadas\n",
    "dates_to_zero = [\n",
    "    \"01/01/25\",\"02/01/25\",\"03/01/25\",\"04/01/25\",\"05/01/25\",\"06/01/25\",\"07/01/25\",\n",
    "    \"08/01/25\",\"09/01/25\",\"10/01/25\",\"11/01/25\",\"12/01/25\",\"13/01/25\",\"14/01/25\",\n",
    "    \"15/01/25\",\"16/01/25\",\"17/01/25\",\"18/01/25\",\"19/01/25\",\"20/01/25\",\"21/01/25\",\n",
    "    \"22/01/25\",\"23/01/25\",\"24/01/25\",\"25/01/25\",\"26/01/25\",\"27/01/25\",\"28/01/25\",\n",
    "    \"29/01/25\",\"30/01/25\",\"31/01/25\",\"01/02/25\",\"02/02/25\",\"03/02/25\",\"04/02/25\",\n",
    "    \"05/02/25\",\"06/02/25\",\"07/02/25\",\"08/02/25\",\"09/02/25\",\"10/02/25\",\"11/02/25\",\n",
    "    \"12/02/25\",\"13/02/25\",\"14/02/25\",\"15/02/25\",\"16/02/25\",\"17/02/25\",\"18/02/25\",\n",
    "    \"19/02/25\",\"20/02/25\",\"21/02/25\",\"22/02/25\",\"23/02/25\",\"24/02/25\",\"25/02/25\",\n",
    "    \"26/02/25\",\"27/02/25\",\"28/02/25\",\"01/03/25\",\"02/03/25\",\"03/03/25\",\"04/03/25\",\n",
    "    \"05/03/25\",\"06/03/25\",\"07/03/25\",\"08/03/25\",\"09/03/25\",\"10/03/25\",\"11/03/25\",\n",
    "    \"12/03/25\",\"13/03/25\",\"14/03/25\",\"15/03/25\",\"16/03/25\",\"17/03/25\",\"18/03/25\",\n",
    "    \"19/03/25\",\"20/03/25\",\"21/03/25\",\"22/03/25\",\"23/03/25\",\"24/03/25\",\"25/03/25\",\n",
    "    \"26/03/25\",\"27/03/25\",\"28/03/25\",\"29/03/25\",\"30/03/25\",\"31/03/25\",\"01/04/25\",\n",
    "    \"02/04/25\",\"03/04/25\"\n",
    "]\n",
    "# Parsear a datetime\n",
    "zero_days = pd.to_datetime(dates_to_zero, dayfirst=True)\n",
    "\n",
    "# Asegurarnos de que combined_copy['day'] es datetime\n",
    "combined_copy['day'] = pd.to_datetime(combined_copy['day'], dayfirst=True)\n",
    "\n",
    "# Aplicar la regla: en esas date inventory = 0\n",
    "combined_copy.loc[ combined_copy['day'].isin(zero_days), 'inventory' ] = 0\n",
    "\n",
    "# 8. (Opcional) Revisa que se aplicó\n",
    "print(combined_copy.loc[ combined_copy['day'].isin(zero_days), ['day','inventory'] ].drop_duplicates().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcf9f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BORRAR data INICIALES SIN sales\n",
    "\n",
    "# Asegúrate de que sea datetime\n",
    "combined_copy['day'] = pd.to_datetime(combined_copy['day'], dayfirst=True)\n",
    "\n",
    "# Filtrar filas a partir del 6 de agosto de 2024 (inclusive)\n",
    "combined_copy = combined_copy[ combined_copy['day'] >= pd.to_datetime('2024-08-06') ].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83602c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REVISAR DISCREPANCIAS DE INsalesRIO Y EXPLICARLAS\n",
    "\n",
    "\n",
    "# 1. Extrae solo las tres series\n",
    "serie = combined_copy[['total_sessions', 'inventory', 'total_sales']].copy()\n",
    "\n",
    "# 2. Normalización Min–Max\n",
    "for col in serie.columns:\n",
    "    min_, max_ = serie[col].min(), serie[col].max()\n",
    "    serie[col] = (serie[col] - min_) / (max_ - min_)\n",
    "\n",
    "# 3. Gráfico\n",
    "plt.figure(figsize=(10,5))\n",
    "#plt.plot(serie.index, serie['total_sessions'], label='Sessions (scaled)')\n",
    "#plt.plot(serie.index, serie['inventory'],    label='Inventory (scaled)')\n",
    "plt.plot(serie.index, serie['total_sales'],  label='Sales (scaled)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Scaled Value')\n",
    "plt.title('Total Sales')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1d4482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ——————————————————————————————————————————\n",
    "# Asume que `combined_copy` ya está cargado con:\n",
    "# index: no importa (usamos .loc con day)\n",
    "# columnas: 'day', 'total_sessions', 'inventory', 'total_sales'\n",
    "# ——————————————————————————————————————————\n",
    "\n",
    "# 1. Prepara el DataFrame y asegúrate de tener datetime\n",
    "df = combined_copy.copy()\n",
    "df['day'] = pd.to_datetime(df['day'])\n",
    "df = df.set_index('day').sort_index()\n",
    "\n",
    "# 2. Define el hold‑out (últimos 30 días)\n",
    "test_period = 30\n",
    "train = df.iloc[:-test_period]\n",
    "test  = df.iloc[-test_period:]\n",
    "\n",
    "# 3️⃣ Opción 1: imputar faltantes en stock‑out y modelar sales directas\n",
    "\n",
    "# 3.1 Marca como NaN donde no hay stock\n",
    "df1 = train.copy()\n",
    "mask_no_stock = df1['inventory'] <= 0\n",
    "df1.loc[mask_no_stock, 'total_sales'] = np.nan\n",
    "\n",
    "# 3.2 Interpola sales\n",
    "sales_series = df1['total_sales'].asfreq('D').interpolate(method='time')\n",
    "\n",
    "# 3.3 Ajusta SARIMA sobre sales\n",
    "model1 = SARIMAX(sales_series,\n",
    "                 ORDER=(1,1,1),\n",
    "                 SEASONAL_ORDER=(1,1,1,7),\n",
    "                 ENFORCE_STATIONARITY=False,\n",
    "                 ENFORCE_INVERTIBILITY=False)\n",
    "fit1 = model1.fit(disp=False)\n",
    "\n",
    "# 3.4 Forecast sales (opción 1)\n",
    "forecast1 = fit1.get_forecast(steps=test_period).predicted_mean\n",
    "forecast1 = pd.Series(forecast1.values, index=test.index)\n",
    "\n",
    "# 4️⃣ Opción 3: modelar sesiones + tasa de conversión\n",
    "\n",
    "# 4.1 Calcula conversion rate promedio en train\n",
    "train = train.copy()\n",
    "train['conversion_rate'] = train['total_sales'] / train['total_sessions']\n",
    "cr_mean = train['conversion_rate'].mean()\n",
    "\n",
    "# 4.2 Ajusta SARIMA sobre sesiones\n",
    "sessions_series = train['total_sessions'].asfreq('D').interpolate(method='time')\n",
    "model3 = SARIMAX(sessions_series,\n",
    "                 ORDER=(1,1,1),\n",
    "                 SEASONAL_ORDER=(1,1,1,7),\n",
    "                 ENFORCE_STATIONARITY=False,\n",
    "                 ENFORCE_INVERTIBILITY=False)\n",
    "fit3 = model3.fit(disp=False)\n",
    "\n",
    "# 4.3 Pronostica sesiones y convierte a sales\n",
    "forecast_sessions = fit3.get_forecast(steps=test_period).predicted_mean\n",
    "forecast_sessions = pd.Series(forecast_sessions.values, index=test.index)\n",
    "forecast3 = forecast_sessions * cr_mean\n",
    "\n",
    "# 5. Evalúa con RMSE y MAE\n",
    "actual = test['total_sales']\n",
    "\n",
    "def evaluate_model(true, pred, name):\n",
    "    rmse = np.sqrt(mean_squared_error(true, pred))\n",
    "    mae  = mean_absolute_error(true, pred)\n",
    "    print(f\"{name} → RMSE: {rmse:.2f}, MAE: {mae:.2f}\")\n",
    "\n",
    "evaluate_model(actual, forecast1, \"Opción 1 (sales directas SARIMA)\")\n",
    "evaluate_model(actual, forecast3, \"Opción 3 (sessions × avg CR)\")\n",
    "\n",
    "# 6. plot comparativa\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(train.index, train['total_sales'], label='Train Sales')\n",
    "plt.plot(test.index,  actual,                marker='o', label='Actual Sales (Test)')\n",
    "plt.plot(test.index,  forecast1,             marker='x', label='Forecast Opción 1')\n",
    "plt.plot(test.index,  forecast3,             marker='s', label='Forecast Opción 3')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.title('Comparativa de Forecasts: Opción 1 vs Opción 3')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0553325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parte 0: Partimos de tu DataFrame combinado\n",
    "df = combined_copy.copy()\n",
    "\n",
    "# 1. Asegúrate de que 'day' sea datetime y añádelo como índice\n",
    "df['day'] = pd.to_datetime(df['day'], dayfirst=True)  # o sin dayfirst si es YYYY-MM-DD\n",
    "df = df.set_index('day').sort_index()\n",
    "\n",
    "# 2. Crea la columna weekday (0 = lunes … 6 = domingo)\n",
    "df['weekday'] = df.index.weekday\n",
    "\n",
    "# 3. Calcula la Mean de sales y sesiones **para todos los data**, por weekday\n",
    "means = (\n",
    "    df\n",
    "      .groupby('weekday')[['total_sales','total_sessions']]\n",
    "      .mean()\n",
    ")\n",
    "print(\"Mean by weekday:\\n\", means, \"\\n\")\n",
    "\n",
    "# 4. Define máscara de filas a imputar:\n",
    "#    - día en 2025 o posterior\n",
    "#    - inventory ≤ 0 o NaN\n",
    "mask = (df.index.year >= 2025) & ((df['inventory'] <= 0) | (df['inventory'].isna()))\n",
    "print(\"Total filas a imputar:\", mask.sum())\n",
    "\n",
    "# 5. Sustituye las columnas en esas filas según su weekday\n",
    "df.loc[mask, 'total_sales']    = df.loc[mask, 'weekday'].map(means['total_sales'])\n",
    "df.loc[mask, 'total_sessions'] = df.loc[mask, 'weekday'].map(means['total_sessions'])\n",
    "\n",
    "# 6. (Opcional) Marca qué filas fueron imputadas\n",
    "df['imputed'] = False\n",
    "df.loc[mask, 'imputed'] = True\n",
    "\n",
    "# 7. Resultado final\n",
    "combined_imputed = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bc0065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REVISAR DISCREPANCIAS DE INsalesRIO Y EXPLICARLAS\n",
    "\n",
    "\n",
    "# 1. Extrae solo las tres series\n",
    "serie = combined_imputed[['total_sessions', 'inventory', 'total_sales']].copy()\n",
    "\n",
    "# 2. Normalización Min–Max\n",
    "for col in serie.columns:\n",
    "    min_, max_ = serie[col].min(), serie[col].max()\n",
    "    serie[col] = (serie[col] - min_) / (max_ - min_)\n",
    "\n",
    "# 3. Gráfico\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(serie.index, serie['total_sessions'], label='Sessions (scaled)')\n",
    "#plt.plot(serie.index, serie['inventory'],    label='Inventory (scaled)')\n",
    "plt.plot(serie.index, serie['total_sales'],  label='Sales (scaled)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Scaled Value')\n",
    "plt.title('Inventory vs. Total Sessions with Demand Modification')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7963e3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASET FINAL PARA TRABAJAR: IGNORAR PERIODO DE STOCKOUT PARA EVITAR QUE AFECTE Forecast\n",
    "\n",
    "combined_final = combined_imputed\n",
    "combined_final = combined_final.drop(columns=['weekday'])\n",
    "combined_final = combined_final.rename(columns={'imputed': 'ignore'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8476e085",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Partimos de tu DataFrame final\n",
    "df = combined_final.copy()\n",
    "\n",
    "# 2. Asegúrate de que el índice sea datetime\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# 3. Convierte las columnas a numérico y el flag a booleano\n",
    "df['total_sales']    = pd.to_numeric(df['total_sales'], errors='coerce')\n",
    "df['total_sessions'] = pd.to_numeric(df['total_sessions'], errors='coerce')\n",
    "df['ignore']         = df['ignore'].astype(bool)\n",
    "\n",
    "# 4. Filtra solo filas válidas (ignore == False) y sin NaN en sales\n",
    "train = df.loc[~df['ignore']].dropna(subset=['total_sales'])\n",
    "\n",
    "# 5. Extrae la serie de sales a frecuencia diaria\n",
    "sales_series = train['total_sales'].asfreq('D').fillna(method='ffill')\n",
    "\n",
    "# 6. Ajusta tu SARIMA óptimo (por ejemplo (2,0,2)x(0,1,1,7))\n",
    "model = SARIMAX(\n",
    "    sales_series,\n",
    "    ORDER=(2,0,2),\n",
    "    SEASONAL_ORDER=(0,1,1,7),\n",
    "    ENFORCE_STATIONARITY=False,\n",
    "    ENFORCE_INVERTIBILITY=False\n",
    ")\n",
    "fit = model.fit(disp=False)\n",
    "print(fit.summary())\n",
    "\n",
    "# 7. Forecast (por ejemplo 30 días)\n",
    "forecast = fit.get_forecast(steps=30)\n",
    "pred = forecast.predicted_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8e7145",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Partimos de lo ya calculado antes:\n",
    "# df            = combined_final con índice datetime\n",
    "# train         = df.loc[~df['ignore']] (serie usada para entrenar)\n",
    "# pred          = forecast.predicted_mean (serie de Forecast)\n",
    "# forecast      = objeto resultado de get_forecast (para bandas de IC)\n",
    "# conf_int      = forecast.conf_int()\n",
    "\n",
    "# 1. Obtén también los intervalos de confianza\n",
    "conf_int = forecast.conf_int(alpha=0.05)  # 95%\n",
    "\n",
    "# 2. Gráfico\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "# Históricos\n",
    "plt.plot(train.index, train['total_sales'], label='Sales', color='C0')\n",
    "\n",
    "# Forecast\n",
    "plt.plot(pred.index, pred, label='Forecast 30 días', color='C1')\n",
    "\n",
    "# Bandas de confianza\n",
    "plt.fill_between(conf_int.index,\n",
    "                 conf_int['lower total_sales'],\n",
    "                 conf_int['upper total_sales'],\n",
    "                 color='C1', alpha=0.2,\n",
    "                 label='IC 95%')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.title('Sales Forecasting (SARIMAX)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea32809",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Recupera residuals históricos, sin NaN\n",
    "resid = fit.resid.dropna().values\n",
    "\n",
    "# 2. parameters de simulación\n",
    "nsim    = 100              # number de caminos Monte Carlo\n",
    "HORIZON = len(pred)        # p.ej. 30 días\n",
    "\n",
    "# 3. Matriz para simulaciones\n",
    "sims_boot = np.zeros((HORIZON, nsim))\n",
    "\n",
    "# 4. Bootstrap de residuals\n",
    "rng = np.random.default_rng()  # generador random\n",
    "for i in range(nsim):\n",
    "    eps = rng.choice(resid, size=HORIZON, replace=True)\n",
    "    sims_boot[:, i] = pred.values + eps\n",
    "    \n",
    "sims_boot = np.maximum(sims_boot, 0)\n",
    "\n",
    "# 5. Gráfico\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "# 5.1 Históricos\n",
    "plt.plot(train.index, train['total_sales'], color='C0', label='Sales')\n",
    "\n",
    "# 5.2 Mean de Forecast\n",
    "plt.plot(pred.index, pred, color='C1', lw=2, label='Forecast (mean)')\n",
    "\n",
    "# 5.3 Trayectorias bootstrap\n",
    "for i in range(nsim):\n",
    "    plt.plot(pred.index, sims_boot[:, i], color='gray', alpha=0.1)\n",
    "\n",
    "# 5.4 confidence interval original\n",
    "conf_int = forecast.conf_int(alpha=0.05)\n",
    "plt.fill_between(conf_int.index,\n",
    "                 conf_int['lower total_sales'],\n",
    "                 conf_int['upper total_sales'],\n",
    "                 color='C1', alpha=0.2,\n",
    "                 label='IC 95% SARIMAX')\n",
    "\n",
    "plt.xlabel('date')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.title('Monte Carlo with Residual Bootstrap')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02183c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# —————————————————————————————\n",
    "# 0. Prepara tu DataFrame final con índice datetime y flag ignore\n",
    "df = combined_final.copy()\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df['total_sales'] = pd.to_numeric(df['total_sales'], errors='coerce')\n",
    "df['ignore']      = df['ignore'].astype(bool)\n",
    "\n",
    "# 1. Divide en train/test (últimos 30 días para test)\n",
    "series     = df.loc[~df['ignore'], 'total_sales']\n",
    "h_test     = 30\n",
    "train_full = series.iloc[:-h_test]\n",
    "test       = series.iloc[-h_test:]\n",
    "\n",
    "# 2. parameters SARIMA que descubriste\n",
    "ORDER          = (2,0,2)\n",
    "SEASONAL_ORDER = (0,1,1,7)\n",
    "\n",
    "# 3. number de simulaciones bootstrap\n",
    "nsim = 500\n",
    "\n",
    "# 4. Arrays para savar results\n",
    "pred_mean = []\n",
    "p20_list   = []\n",
    "p80_list   = []\n",
    "p2_5_list  = []\n",
    "p97_5_list = []\n",
    "\n",
    "# 5. Back‑test día a día\n",
    "for i in range(h_test):\n",
    "    # 5.1 training incremental\n",
    "    train_i = pd.concat([train_full, test.iloc[:i]])\n",
    "    \n",
    "    # 5.2 ajusta SARIMA\n",
    "    model = SARIMAX(train_i,\n",
    "                    ORDER=ORDER,\n",
    "                    SEASONAL_ORDER=SEASONAL_ORDER,\n",
    "                    ENFORCE_STATIONARITY=False,\n",
    "                    ENFORCE_INVERTIBILITY=False)\n",
    "    fit_i = model.fit(disp=False)\n",
    "    \n",
    "    # 5.3 Forecast 1 paso\n",
    "    fc = fit_i.get_forecast(steps=1)\n",
    "    mu = fc.predicted_mean.iloc[0]\n",
    "    \n",
    "    # 5.4 bootstrap de residuals + cap en 0\n",
    "    resid = fit_i.resid.dropna().values\n",
    "    sims  = np.random.choice(resid, size=(nsim,), replace=True) + mu\n",
    "    sims  = np.clip(sims, 0, None)\n",
    "    \n",
    "    # 5.5 percentiles: 20–80 para banda central, 2.5–97.5 para extremo\n",
    "    p20, p80    = np.percentile(sims, [20, 80])\n",
    "    p2_5, p97_5 = np.percentile(sims, [3, 97])\n",
    "    \n",
    "    # 5.6 almacenar\n",
    "    pred_mean.append(mu)\n",
    "    p20_list.append(p20)\n",
    "    p80_list.append(p80)\n",
    "    p2_5_list.append(p2_5)\n",
    "    p97_5_list.append(p97_5)\n",
    "\n",
    "# 6. Organiza results en DataFrame\n",
    "results = pd.DataFrame({\n",
    "    'actual':  test.values,\n",
    "    'mean_fc': pred_mean,\n",
    "    'p20':     p20_list,\n",
    "    'p80':     p80_list,\n",
    "    'p2.5':    p2_5_list,\n",
    "    'p97.5':   p97_5_list,\n",
    "}, index=test.index)\n",
    "\n",
    "# 7. metric de error\n",
    "mae   = mean_absolute_error(results['actual'], results['mean_fc'])\n",
    "rmse  = np.sqrt(mean_squared_error(results['actual'], results['mean_fc']))\n",
    "\n",
    "# Cobertura de intervalos\n",
    "cov_20_80 = ((results.actual >= results.p20) & (results.actual <= results.p80)).mean()\n",
    "cov_95    = ((results.actual >= results['p2.5']) & (results.actual <= results['p97.5'])).mean()\n",
    "\n",
    "print(f\"MAE: {mae:.2f}, RMSE: {rmse:.2f}\")\n",
    "print(f\"Cobertura 20–80%: {cov_20_80:.2%}\")\n",
    "print(f\"Cobertura 95%: {cov_95:.2%}\")\n",
    "\n",
    "# 8. plot comparativa\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(train_full.index, train_full, color='gray', alpha=0.6, label='Train')\n",
    "plt.plot(results.index, results['actual'], 'o-', label='Actual Test')\n",
    "plt.plot(results.index, results['mean_fc'], 's--', label='Forecast Mean')\n",
    "\n",
    "# Banda 20–80%\n",
    "plt.fill_between(results.index, results.p20, results.p80,\n",
    "                 color='C2', alpha=0.3, label='20–80% PI')\n",
    "\n",
    "# Banda 95%\n",
    "plt.fill_between(results.index, results['p2.5'], results['p97.5'],\n",
    "                 color='C1', alpha=0.1, label='95% PI')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.title('Backtest: SARIMAX + Bootstrap')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0509c4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Prepare the historical series without the rows marked as ignore\n",
    "df = combined_final.copy()\n",
    "df.index = pd.to_datetime(df.index)\n",
    "sales = df.loc[~df['ignore'], 'total_sales'].astype(float)\n",
    "# Rellenar huecos si los hubiera (opcional)\n",
    "sales = sales.asfreq('D').fillna(method='ffill')\n",
    "\n",
    "# 2. Adjust your final SARIMAX over the entire series\n",
    "model = SARIMAX(\n",
    "    sales,\n",
    "    ORDER=(2,0,2),\n",
    "    SEASONAL_ORDER=(0,1,1,7),\n",
    "    ENFORCE_STATIONARITY=False,\n",
    "    ENFORCE_INVERTIBILITY=False\n",
    ")\n",
    "fit = model.fit(disp=False)\n",
    "\n",
    "# 3. Average forecast for the next 15 days\n",
    "HORIZON = 15\n",
    "fc = fit.get_forecast(steps=HORIZON)\n",
    "mean_fc = fc.predicted_mean\n",
    "\n",
    "# 4. Bootstrap residuals to create uncertainty bands\n",
    "resid = fit.resid.dropna().values\n",
    "nsim  = 500\n",
    "\n",
    "# We simulate nsim trajectories of length `HORIZON`\n",
    "sims = np.zeros((HORIZON, nsim))\n",
    "for i in range(nsim):\n",
    "    eps = np.random.choice(resid, size=HORIZON, replace=True)\n",
    "    sims[:, i] = mean_fc.values + eps\n",
    "# prevent negative sales\n",
    "sims = np.clip(sims, 0, None)\n",
    "\n",
    "# 5. Calculate central and extreme percentiles\n",
    "p20   = np.percentile(sims, 20, axis=1)\n",
    "p80   = np.percentile(sims, 80, axis=1)\n",
    "p3    = np.percentile(sims, 3,  axis=1)\n",
    "p97   = np.percentile(sims, 97, axis=1)\n",
    "\n",
    "# 6. Assemble a DataFrame with the forecast\n",
    "future_dates = pd.date_range(start=sales.index[-1] + pd.Timedelta(days=1),\n",
    "                             periods=HORIZON, freq='D')\n",
    "forecast_df = pd.DataFrame({\n",
    "    'mean_fc':   mean_fc.values,\n",
    "    'p20':       p20,\n",
    "    'p80':       p80,\n",
    "    'p3':        p3,\n",
    "    'p97':       p97\n",
    "}, index=future_dates)\n",
    "\n",
    "# 7. History graph + forecast + bands\n",
    "plt.figure(figsize=(12,6))\n",
    "# Historic\n",
    "plt.plot(sales.index, sales, color='C0', label='Histórico')\n",
    "\n",
    "# Average forecast\n",
    "plt.plot(future_dates, forecast_df['mean_fc'], color='C1', lw=2, label='Forecast (Mean)')\n",
    "\n",
    "#  20–80%\n",
    "plt.fill_between(future_dates,\n",
    "                 forecast_df['p20'],\n",
    "                 forecast_df['p80'],\n",
    "                 color='C2', alpha=0.3, label='20–80% PI')\n",
    "\n",
    "#  3–97%\n",
    "plt.fill_between(future_dates,\n",
    "                 forecast_df['p3'],\n",
    "                 forecast_df['p97'],\n",
    "                 color='C1', alpha=0.1, label='3–97% PI')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.title('15-day forecast with SARIMAX + Residual Bootstrap')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 8. Display the forecast DataFrame\n",
    "print(forecast_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3258c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre del archivo que quieres crear\n",
    "nombre_archivo = \"combined_final.csv\"\n",
    "\n",
    "# Construimos la ruta completa\n",
    "ruta_salida = os.path.join(ruta_base, nombre_archivo)\n",
    "\n",
    "# savamos el DataFrame sin el índice\n",
    "combined_final.to_csv(ruta_salida, index=True, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"Archivo savado en: {ruta_salida}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b63713e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
